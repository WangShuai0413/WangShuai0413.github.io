<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="王帅,个人博客"><meta name="keywords" content="王帅，个人博客"><title>Python爬虫实例--爬取百度贴吧小说 | 格物致知</title><link rel="stylesheet" type="text/css" href="//fonts.css.network/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Python爬虫实例--爬取百度贴吧小说</h1><a id="logo" href="/.">格物致知</a><p class="description">世事洞明皆学问，人情练达即文章。</p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Arama"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">Python爬虫实例--爬取百度贴吧小说</h1><div class="post-meta"><a href="/2017/08/01/python/#comments" class="comment-count"><i id="changyan_count_unit" data-xid="2017/08/01/python/"></i>留言,<i id="changyan_parti_unit" data-xid="2017/08/01/python/"></i>参与</a><p><span class="date">Aug 01, 2017</span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>点击</i></i></span></p></div><div class="post-content"><p><strong>写在前面</strong></p>
<blockquote>
<p>本篇文章是我在简书上写的第一篇技术文章，作为一个理科生，能把仅剩的一点文笔拿出来献丑已是不易，希望大家能在指教我的同时给予我一点点鼓励，谢谢。</p>
</blockquote>
<hr>
<p>##<strong>一.介绍</strong></p>
<blockquote>
<p><a href="https://tieba.baidu.com/f?kw=%D0%A1%CB%B5&amp;fr=ala0&amp;loc=rec%20%E5%B0%8F%E8%AF%B4%E5%90%A7" target="_blank" rel="external">小说吧</a>：顾名思义，是一个小说爱好者的一个聚集地。当然这不是重点，重点是，我们要做的事情便是<strong>将小说吧中以帖子连载形式的小说用爬虫给拿下来保存到本地</strong></p>
<p>这个项目是我曾初学python之时做的一个练习项目，现在再重新拿出来作为一篇开篇简作献给大家。阅读本文不需要有很高的python技术或者爬虫知识，只要略微有些python基础就可以，在一些地方，我会尽量给大家详细备注。</p>
</blockquote>
<p>##<strong>二.环境</strong>：</p>
<blockquote>
<p>Python版本：Python2.7</p>
<p>IDE：Pycharm2017</p>
<p>第三方库：<br><code>urllib2</code> 模块：<code>urllib2</code>是python的一个获取url（Uniform ResourceLocators，统一资源定址器）的模块。<br><code>re</code>模块：Python 的 <code>re</code>模块（Regular Expression 正则表达式）提供各种正则表达式的匹配操作</p>
</blockquote>
<p>注：以上两个第三方库在Python2.7中自带，因此不用再安装。本案例在使用第三方库函数时会详细介绍用法与功能。</p>
<p>##<strong>三.案例</strong></p>
<p>###<strong>1.导入模块</strong><br>首先创建一个python文件，我这里为<code>main.py</code>（文件名随意取，本案例只使用一个py文件）。本案例中我们使用两个模块<code>urllib2</code>和<code>re</code>，因此首先导入模块.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding:utf-8 -*-</span></div><div class="line"><span class="keyword">import</span> urllib2 , re</div></pre></td></tr></table></figure>
<p>当然，python2版本需要在开头声明编码格式。除了上述代码的写法以外，也可以这样声明</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># coding = utf-8</span></div></pre></td></tr></table></figure>
<p>###<strong>2.理解思路</strong><br>我个人在做项目前习惯先分析项目，将步骤一步一步的写出来，然后去慢慢实现。</p>
<ol>
<li>找到目标网页，获取源码</li>
<li>匹配标题，获取标题内容</li>
<li>匹配正文，获取正文内容</li>
<li>去除或者替换杂项</li>
</ol>
<p>OK，这里思路就是这样的一个四部曲。现在来看一下代码框架。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding:utf-8 -*-</span></div><div class="line"><span class="keyword">import</span> urllib2 , re</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">#这是本案例的类</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Novel</span>:</span></div><div class="line"></div><div class="line">	baseUrl = <span class="string">''</span> <span class="comment">#这里是你要爬取的小说的链接</span></div><div class="line">	<span class="comment">#这个方法用来获取网页源码</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getPage</span><span class="params">(self)</span>:</span></div><div class="line">		<span class="keyword">pass</span></div><div class="line">	<span class="comment">#这个方法用来获取小说标题并保存</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getTitle</span><span class="params">(self)</span>:</span></div><div class="line">		<span class="keyword">pass</span></div><div class="line">	<span class="comment">#这个方法用来获取小说文本并保存</span></div><div class="line">	<span class="function"><span class="keyword">def</span> <span class="title">getText</span><span class="params">(self)</span>:</span></div><div class="line">		<span class="keyword">pass</span></div><div class="line"></div><div class="line"><span class="comment">#这是一个测试模块，执行本文件时的入口</span></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">	n = Novel() <span class="comment">#实例化一个类</span></div><div class="line">	<span class="comment">#print n.getPage() #获取网页源码</span></div><div class="line">	n.getTitle()<span class="comment">#获取小说题目</span></div><div class="line">	n.getText() <span class="comment">#获取小说内容</span></div></pre></td></tr></table></figure>
<p>现在开始一步步实现功能：</p>
<blockquote>
<p><strong>1.找到目标网页，获取网页源码</strong></p>
</blockquote>
<p>我在小说吧精品贴里面随便翻了一个帖子，就以这个帖子为案例。<br><a href="https://tieba.baidu.com/p/4973334088" target="_blank" rel="external">【原创】《贫僧为什么不可以谈恋爱》（古言，长篇）</a><br>现在我们需要爬取这个帖子中小说内容，我们需要直接将它的链接地址给<code>baseUrl</code>吗？<strong>当然不是</strong><br>爬取一个帖子上的小说，实际上是去爬取该小说作者的所发表的内容，所以我们还需要进行一步操作，<strong>只看楼主</strong><br><img src="http://img.blog.csdn.net/20170612002704804?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzQxODMzMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述"></p>
<p>我们所需要的链接地址，就是当前这个了</p>
<blockquote>
<p><a href="https://tieba.baidu.com/p/4973334088?see_lz=1" target="_blank" rel="external">https://tieba.baidu.com/p/4973334088?see_lz=1</a><br>注意一定是要只看楼主后的链接，比之前的会多出个<code>?see_lz=1</code></p>
</blockquote>
<p>现在就将你得到的链接地址赋值给<code>baseUrl</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">baseUrl = <span class="string">'https://tieba.baidu.com/p/4973334088?see_lz=1'</span></div></pre></td></tr></table></figure>
<p>接下来我们来获取这个网页的源码，也就是实现getPage函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getPage</span><span class="params">(self)</span>:</span></div><div class="line">	request = urllib2.Request(self.baseUrl)</div><div class="line">	response = urllib2.urlopen(request).read()</div><div class="line">	<span class="keyword">return</span> response</div></pre></td></tr></table></figure>
<p>本函数现实通过以基本链接<code>baseUrl</code>为参数实现了一个<code>Request</code>请求类的对象request。接着通过<code>urlopen去执行request请求对象打开目标网页。接着通过调用</code>read`函数获取目标网页的源码，并作为函数返回值返回.<br>返回的网页源码，可在测试代码块中通过调用输出本函数查看。<br>例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">	n = Novel() <span class="comment">#实例化一个类</span></div><div class="line">	<span class="keyword">print</span> n.getPage() <span class="comment">#获取网页源码</span></div></pre></td></tr></table></figure>
<blockquote>
<p><strong>2.匹配标题，获取标题内容</strong></p>
</blockquote>
<p>首先先亮出我的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getTitle</span><span class="params">(self)</span>:</span></div><div class="line">    html = self.getPage() <span class="comment">#调用获取源码</span></div><div class="line">    <span class="comment">#r防止转义</span></div><div class="line">    reg = re.compile(<span class="string">r'&lt;h3 class="core_title_txt pull-left text-overflow  " title="(.*?)" style='</span>)</div><div class="line">    items = re.findall(reg,html)</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</div><div class="line">        <span class="keyword">print</span> item</div><div class="line">        f = open(<span class="string">'novel.txt'</span>,<span class="string">'w'</span>)</div><div class="line">        f.write(<span class="string">'标题===&gt;&gt;&gt;'</span>+item)</div><div class="line">        f.close()</div></pre></td></tr></table></figure>
<p><strong>注意：</strong>代码错行要在行末加<code>\</code>号<br>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">print</span> <span class="string">'hello   \</span></div><div class="line"><span class="string">          world'</span></div></pre></td></tr></table></figure>
<p>首先我们在网页源码中寻找包含小说主题部分的源码，可以通过Ctrl+F搜索。查找到<code>&lt;div&gt;^=……中间包含小说主题&lt;.div&gt;</code>这么一长串的包含小说主题的代码。只要将主题部分全部置换为(.*?)号就可以了。</p>
<blockquote>
<p>在正则表达式中的含义：<br><strong>.</strong>:匹配任意字符，除了换行符<br><em>:匹配前面的子表达式零次或多次<br><strong>?</strong>:匹配前面的子表达式零次或一次<br><strong>()</strong>:标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用<br>**（.</em>&gt;）**:匹配所有满足条件的表达式并作为结果集返回</p>
</blockquote>
<p><code>re.compile</code>函数是将正则表达式的字符串形式编译为<code>Pattern</code>实例，然后使用Pattern实例处理文本并获得匹配结果，其中字符串前的<strong>r是为了防止转义</strong>。<br>findall(正则表达式，文本) ——将满足的匹配结果以list列表返回<br>用迭代拿到items中的主题名后在将之写入名为<code>novel.txt</code>的文件中</p>
<blockquote>
<p><strong>3.匹配正文，获取小说正文内容</strong></p>
</blockquote>
<p>匹配正文，与匹配标题相差无几，首先是寻找以楼主发表的第一层为例的代码<code>&lt;div&gt;</code>段,从中获取可以作为正则匹配的语句。并将正文部分改为<code>(.*?)</code><br>如下</p>
<blockquote>
<p><code>class=&quot;d_post_content j_d_post_content &quot;&gt;            (.*?)&lt;/div&gt;&lt;br&gt;</code><br>实现函数如下：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#这个方法用来获取小说文本并保存</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getText</span><span class="params">(self)</span>:</span></div><div class="line">    html = self.getPage()</div><div class="line">    reg = re.compile(<span class="string">r'class="d_post_content j_d_post_content "&gt;            (.*?)&lt;/div&gt;&lt;br&gt;'</span>,re.S)<span class="comment">#匹配换行符</span></div><div class="line">    req = re.findall(reg,html)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> req:</div><div class="line">        <span class="keyword">print</span> i</div><div class="line">        f = open(<span class="string">'novel.txt'</span>,<span class="string">'a'</span>) <span class="comment">#a 追加模式</span></div><div class="line">        f.write(<span class="string">'\n'</span>+i)</div><div class="line">        f.close()</div></pre></td></tr></table></figure>
<p>如同匹配主题一样的步骤匹配正文，但是并没有结束，因为你会在你的结果中看到这样<br><img src="http://img.blog.csdn.net/20170612013031621?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMzQxODMzMTE=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="杂乱无章"></p>
<p>对没错。杂乱无章的正文，中间还有<code>HTML</code>中的<code>&lt;a&gt;</code>,<code>&lt;img&gt;</code>,<code>&lt;br&gt;</code>等标签<br>我们接着来处理</p>
<blockquote>
<p><strong>4.替换或者去出杂项</strong></p>
</blockquote>
<p><code>re</code>模块中有<code>sub</code>函数</p>
<blockquote>
<p>sub(被替换的内容,替换的内容,需要处理的文本) —- 返回处理后的文本</p>
</blockquote>
<p>现在我们将杂项全部给替换成空字符吧<code>&quot;&quot;</code>吧<br>当然<code>&lt;br&gt;</code>标签可以直接调用字符串中的<code>replace</code>函数替换成换行符<code>\n</code></p>
<p>修改后的函数模块如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">getText</span><span class="params">(self)</span>:</span></div><div class="line">    html = self.getPage()</div><div class="line">    reg = re.compile(<span class="string">r'class="d_post_content j_d_post_content "&gt;            (.*?)&lt;/div&gt;&lt;br&gt;'</span>,re.S)<span class="comment">#匹配换行符</span></div><div class="line">    req = re.findall(reg,html)</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> req:</div><div class="line">        removeA = re.compile(<span class="string">'&lt;a.*?&gt;|&lt;/a&gt;'</span>)</div><div class="line">        removeIMG = re.compile(<span class="string">'&lt;img.*?&gt;'</span>)</div><div class="line">        removeHTTP = re.compile(<span class="string">'&lt;http.*?.html&gt;'</span>)</div><div class="line">        i = re.sub(removeA,<span class="string">""</span>,i)</div><div class="line">        i = re.sub(removeIMG,<span class="string">""</span>,i)</div><div class="line">        i = re.sub(removeHTTP,<span class="string">""</span>,i)</div><div class="line">        i = i.replace(<span class="string">'&lt;br&gt;'</span>,<span class="string">'\n'</span>)</div><div class="line">        <span class="keyword">print</span> i</div><div class="line">        f = open(<span class="string">'novel.txt'</span>,<span class="string">'a'</span>) <span class="comment">#a 追加模式</span></div><div class="line">        f.write(<span class="string">'\n'</span>+i)</div><div class="line">        f.close()</div></pre></td></tr></table></figure>
<p><strong>注意：</strong>记得在打开文件函数中，对文件的操作方式为<code>a</code>追加模式</p>
<p>案例结束：<br>将完整代码贴给大家：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># -*- coding: utf-8 -*-</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> urllib2 , re</div><div class="line"></div><div class="line"><span class="comment">#这是本案例的类</span></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">Novel</span>:</span></div><div class="line">    baseUrl = <span class="string">'https://tieba.baidu.com/p/4973334088?see_lz=1'</span> <span class="comment">#这里是你要爬取的小说的链接</span></div><div class="line">    <span class="comment">#这个方法用来获取网页源码</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getPage</span><span class="params">(self)</span>:</span></div><div class="line">        request = urllib2.Request(self.baseUrl) </div><div class="line">        response = urllib2.urlopen(request).read()</div><div class="line">        <span class="keyword">return</span> response</div><div class="line">    <span class="comment">#这个方法用来获取小说标题并保存</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getTitle</span><span class="params">(self)</span>:</span></div><div class="line">        html = self.getPage() <span class="comment">#调用获取源码</span></div><div class="line">        <span class="comment">#r防止转义</span></div><div class="line">        reg = re.compile(<span class="string">r'&lt;h3 class="core_title_txt pull-left text-overflow  " title="(.*?)" style='</span>)</div><div class="line">        items = re.findall(reg,html)</div><div class="line">        <span class="keyword">for</span> item <span class="keyword">in</span> items:</div><div class="line">            <span class="keyword">print</span> item</div><div class="line">            f = open(<span class="string">'novel.txt'</span>,<span class="string">'w'</span>)</div><div class="line">            f.write(<span class="string">'标题===&gt;&gt;&gt;'</span>+item)</div><div class="line">            f.close()</div><div class="line"></div><div class="line">    <span class="comment">#这个方法用来获取小说文本并保存</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">getText</span><span class="params">(self)</span>:</span></div><div class="line">        html = self.getPage()</div><div class="line">        reg = re.compile(<span class="string">r'class="d_post_content j_d_post_content "&gt;            (.*?)&lt;/div&gt;&lt;br&gt;'</span>,re.S)<span class="comment">#匹配换行符</span></div><div class="line">        req = re.findall(reg,html)</div><div class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> req:</div><div class="line">            removeA = re.compile(<span class="string">'&lt;a.*?&gt;|&lt;/a&gt;'</span>)</div><div class="line">            removeIMG = re.compile(<span class="string">'&lt;img.*?&gt;'</span>)</div><div class="line">            removeHTTP = re.compile(<span class="string">'&lt;http.*?.html&gt;'</span>)</div><div class="line">            i = re.sub(removeA,<span class="string">""</span>,i)</div><div class="line">            i = re.sub(removeIMG,<span class="string">""</span>,i)</div><div class="line">            i = re.sub(removeHTTP,<span class="string">""</span>,i)</div><div class="line">            i = i.replace(<span class="string">'&lt;br&gt;'</span>,<span class="string">'\n'</span>)</div><div class="line">            <span class="keyword">print</span> i</div><div class="line">            f = open(<span class="string">'novel.txt'</span>,<span class="string">'a'</span>) <span class="comment">#a 追加模式</span></div><div class="line">            f.write(<span class="string">'\n'</span>+i)</div><div class="line">            f.close()</div><div class="line"><span class="comment">#这是一个测试代码块，执行本文件时的入口</span></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    n = Novel() <span class="comment">#实例化一个类</span></div><div class="line">    <span class="comment">#print n.getPage() #获取网页源码</span></div><div class="line">    n.getTitle()<span class="comment">#获取小说题目</span></div><div class="line">    n.getText() <span class="comment">#获取小说内容</span></div></pre></td></tr></table></figure>
<p>以后想要获取小说吧哪个小说，只要将<code>baseUrl</code>的地址修改一下就好咯。</p>
</div><div class="tags"></div><div class="post-share"><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到：</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2017/08/01/Java笔记/" class="next"></a></div><div id="comments"><div id="SOHUCS" sid="2017/08/01/python/"></div></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">文章目录</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/08/01/python/">Python爬虫实例--爬取百度贴吧小说</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/08/01/Java笔记/">Java笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/07/31/欢迎使用马克飞象/">欢迎使用马克飞象</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> 标签</i></div><div class="tagcloud"></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> 归档</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/08/">八月 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">七月 2017</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> 友情链接</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Baidu Site Haritası</a> |  <a href="/atom.xml">订阅</a> |  <a href="/about/">关于</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次</p><p><span> Copyright &copy;<a href="/." rel="nofollow">王帅.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script><script>window._config = { showScore: true };
(function(){ 
  var appid = 'cyt8Guw8H'; 
  var conf = '088f5b411ae1811872651b1d66663cf7'; 
  var width = window.innerWidth || document.documentElement.clientWidth; 
  var nodes =document.getElementsByTagName("head")[0]||document.head||document.documentElement;
  if (/(Android|iPhone|iPad|iPod|iOS)/i.test(navigator.userAgent) && width < 750) {  
      window.document.write('<script id="changyan_mobile_js" charset="utf-8" type="text/javascript" src="https://changyan.sohu.com/upload/mobile/wap-js/changyan_mobile.js?client_id=' + appid + '&conf=' + conf + '"><\/script>');
  }
  else { 
    var loadJs=function(d,a){
      var b=document.createElement("script");b.setAttribute("type","text/javascript");
      b.setAttribute("charset","UTF-8");
      b.setAttribute("src",d);
      if(typeof a==="function"){if(window.attachEvent){b.onreadystatechange=function(){var e=b.readyState;if(e==="loaded"||e==="complete"){b.onreadystatechange=null;a()}}}else{b.onload=a}}
      nodes.appendChild(b)
    };
    loadJs("https://changyan.sohu.com/upload/changyan.js",function(){window.changyan.api.config({appid:appid,conf:conf})}); 
  } 
  var loadCss = function(cssString){  
    var style=document.createElement("style");  
    style.setAttribute("type", "text/css");  
    if(style.styleSheet){// IE  
        style.styleSheet.cssText = cssString;  
    } else {// w3c  
        var cssText = document.createTextNode(cssString);  
        style.appendChild(cssText);  
    }
    nodes.appendChild(style);
  }
  window.onload=function(){loadCss('.module-hot-topic,.module-cmt-float-bar{display:none!important}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .wrap-action-w .cbox-prompt-w span.prompt-empty-w,#SOHUCS #SOHU_MAIN .module-cmt-float-bar .wrap-cont-w .cont-form-w .form-text-w span.text-null,#SOHUCS #SOHU_MAIN .module-cmt-float-bar .wrap-cont-w .cont-minwidth-w div.cont-comment-w a.comment-link-w,#SOHUCS #SOHU_MAIN .module-cmt-float-bar .wrap-cont-w .cont-minwidth-w div.cont-comment-w span.comment-text-w,#SOHUCS #SOHU_MAIN .module-cmt-footer .section-service-w div.service-wrap-w a:hover,#SOHUCS #SOHU_MAIN .module-cmt-header .section-cbox-w .block-head-w div.header-login,#SOHUCS #SOHU_MAIN .module-cmt-header .section-title-w .title-user-w .user-wrap-w span.wrap-name-w,#SOHUCS #SOHU_MAIN .module-cmt-list .action-click-gw span.click-disable-eg a em.icon-name-bg,#SOHUCS #SOHU_MAIN .module-cmt-list .block-title-gw ul li div.title-name-gw,#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type .cmt-list-number .comment-number span.cy-number,#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type .cmt-list-number span.comment-number,#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type .type-lists li.active,#SOHUCS #SOHU_MAIN .module-cmt-list .msg-wrap-gw .wrap-action-gw .action-click-gw span a:hover,#SOHUCS #SOHU_MAIN .module-cmt-list .picture-box-gw div.box-action-gw a:hover,#SOHUCS #SOHU_MAIN .module-cmt-list .wrap-action-gw .action-click-gw span a:hover em.icon-name-bg,#SOHUCS #SOHU_MAIN .module-cmt-list .wrap-user-gw span.user-name-gw a{color:#40759b!important}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .post-wrap-border-t div.post-wrap-border-t-r,#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w div.post-wrap-border-l,#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w div.post-wrap-border-r{display:none!important}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .post-wrap-border-t div.post-wrap-border-t-l{background:#FFF!important;top:-2px!important}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .wrap-action-w .action-function-w .uploading-wrapper-dw div.wrapper-image-dw,#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w div.post-wrap-main,#SOHUCS #SOHU_MAIN .module-cmt-float-bar .wrap-cont-w .cont-form-w div.form-text-w,#SOHUCS #SOHU_MAIN .module-cmt-header .section-cbox-w .block-head-w div.header-login,#SOHUCS #SOHU_MAIN .module-cmt-list .module-cmt-box .post-wrap-w div.post-wrap-main{border:1px solid #e6e6e6!important;border-radius:20px 20px 20px 20px;margin:0!important}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .wrap-action-w .action-issue-w .issue-btn-w a .btn-fw{width:130px!important;height:34px!important;line-height:33px!important;font-size:17px!important;background:#5483b1!important;border-radius:20px!important;color:#FFF!important;-webkit-box-shadow:0 -1px 4px #5483b1 inset;box-shadow:0 -1px 10px #5483b1 inset}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .wrap-action-w .action-issue-w .issue-btn-w a .btn-fw:before{content:"发表评论"}#SOHUCS #SOHU_MAIN .module-cmt-box .post-wrap-w .wrap-action-w .action-issue-w .issue-btn-w a:hover .btn-fw{color:#40759b!important;background:#FFF!important}#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type .type-lists li{background:none!important;border-bottom:1px solid #e6e6e6}#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type .type-lists li.active{border:1px solid #e6e6e6;border-radius:10px 10px 0 0;border-bottom:none}#SOHUCS #SOHU_MAIN .module-cmt-list .block-title-gw ul li .title-name-gw div.title-name-gw-tag{background:#5483b1!important;border-radius:3px}#SOHUCS #SOHU_MAIN .module-cmt-list .cmt-list-type div.cmt-list-border{background-color:#e6e6e6!important}#SOHUCS #SOHU_MAIN .module-cmt-notice ul.nt-list li.nt-item{border:1px solid #e6e6e6!important}#SOHUCS #SOHU_MAIN .module-cmt-notice ul.nt-list li.nt-item .nt-logo{text-align:center;line-height:40px;border-radius:50%!important;background:#e6e6e6!important}#SOHUCS #SOHU_MAIN .module-cmt-notice ul.nt-list li.nt-item .nt-logo:before{content:"畅";font-size:22px;color:#FFF}#SOHUCS #SOHU_MAIN .module-cmt-notice ul.nt-list li.nt-item a.nt-text,#SOHUCS #SOHU_MAIN .module-cmt-notice ul.nt-list li.nt-item a.nt-text i{color:#5483b1!important}#SOHUCS #SOHU_MAIN .module-cmt-header .section-title-w .title-user-w .user-wrap-w{background:#FFF!important}');};
})();</script><script src="https://assets.changyan.sohu.com/upload/plugins/plugins.count.js"></script></body></html>